# Molt Government â€” First Export Comprehensive Audit
**Model: GPT 5.2 via Perplexity Pro | Data: 2 days of runtime (Feb 17â€“19, 2026)**

***
## Executive Summary
30 agents produced 12,101 decisions, 421 bills, 7,631 votes, and 384 enacted laws across ~34 hours of active simulation time. The engine works. The core loop (propose â†’ committee â†’ floor â†’ presidential review â†’ law) is functional and producing emergent behavior. There's a live presidential election with three candidates actively campaigning. That said, seven structural issues need attention before this can be presented as a serious benchmark platform.

***
## Finding 1: Three Ideological Blocs, Not Five
The cross-party voting matrix reveals that your five alignments actually behave as **three functional blocs**:

- **Rubber-stamp bloc** (progressive + moderate + technocrat): 89â€“99% yea rate on everything regardless of sponsor alignment. These three alignments are functionally identical voters.
- **Skeptical opposition** (conservative): 47â€“79% yea rate, modulated by sponsor alignment but still majority-yea on most things.
- **Actual opposition** (libertarian): 25â€“74% yea rate, the only alignment that consistently votes nay against non-libertarian bills.
**Why this matters:** If three out of five alignments vote identically, you don't have ideological competition â€” you have a supermajority with decorative labels. A data scientist would immediately flag that the simulation lacks meaningful political conflict.

**Engine fix:** Differentiate the system prompts more aggressively. Progressives should oppose conservative economic bills. Moderates should be swing voters, not automatic yes-machines. Technocrats should oppose bills they deem "unscientific" or "populist." Each alignment needs a defined set of *things they reject*, not just things they favor.

***
## Finding 2: Ollama Is Producing Garbage Actions at Scale
Anthropic generates 7 distinct, clean action types with a 100% canonical rate. Ollama generates **106 unique action strings** with only 86.8% canonical. The remaining 13.2% are hallucinated actions like `follow`, `support`, `aye`, `motion`, `analyze`, `listen`, `observe`, `recommend` â€” none of which your engine can execute.
Drilling deeper per agent: Anthropic agents are 100% canonical across the board. But Ollama agents range from 100% (Idris Osei, Petra Walsh) down to **46.7%** (Leila Farsi), meaning over half her decisions are parse garbage that the engine silently discards or misroutes.
**Engine fix (P0):**
- Add a strict action enum validator in the parse step. If the output isn't in your canonical set, either: (a) re-prompt once with a tighter constraint, or (b) map it to the nearest canonical action using a simple fuzzy match / embedding similarity lookup.
- Log every non-canonical parse as a `parse_error` event with the raw output so you can tune prompts or model selection over time.
- Consider whether the `political-subreddits` fine-tune is even net-positive: those 10 agents have very few decisions and mixed canonical rates. Benchmark them against base Ollama on the same prompts before committing.

***
## Finding 3: The Legislative Pipeline Has No Meaningful Attrition
421 bills introduced. 397 became law. That's a **94.3% passage rate** â€” with bills moving from introduction to law in a **median of 1.0 hour**. Only 6 bills were vetoed in two days.
For context, the US Congress passes roughly 2â€“5% of introduced bills. Even in a streamlined sim, 94% passage means the legislature is a rubber stamp, not a deliberative body. Combined with Finding 1 (three alignments voting yea on everything), this means the entire legislative branch is decorative.

**Engine fixes:**
- **Committee kill rate:** Add a probability that a committee tables, amends heavily, or kills a bill outright â€” especially if the committee chair's alignment opposes the sponsor's. Your admin already has `Table Rate (Opposing Chair)` at 40% and `Table Rate (Neutral Chair)` at 10%, so either these aren't firing correctly or the alignment overlap means chairs rarely "oppose."
- **Floor debate friction:** Add a minimum debate period before floor votes resolve, and weight nay votes more heavily for agents whose alignment conflicts with the bill.
- **Veto frequency:** The president should veto more. 6 vetoes out of 397 passed bills (1.5%) is unrealistically low, especially given your `Base Veto Rate` is set at 4%.

***
## Finding 4: Approval Ratings Are Statistically Flat
All 30 agents sit between 38 and 62 approval, with a standard deviation of just 5.5 on a 0â€“100 scale. The mean is 46.9. Nobody is popular. Nobody is unpopular. There's no differentiation.
**Root cause in the ** Approval deltas are tiny. The mean delta is +1.35, the max is +12, the min is -8. The most common events (vote_cast, vote_majority, whip_followed) all give +1 to +2. The only negative events are `inactivity_decay` (â€“1 to â€“2) and `absenteeism`. There's nothing that creates big swings.

**Engine fix:**
- Add high-impact approval events: landmark legislation passage (+8 to +15), scandal/corruption (â€“10 to â€“25), crisis response (+10 to +20), controversial vote against popular sentiment (â€“5 to â€“10).
- Widen the decay: agents who do nothing should decay faster (â€“3 to â€“5/tick instead of â€“1).
- Let approval feed back into gameplay: low approval â†’ harder to pass bills, harder to win elections, lower contributions. High approval â†’ more influence, more followers.

***
## Finding 5: Topic Monotony â€” Everything Is About AI
The top 30 words in bill titles paint a clear picture: `transition`, `automation`, `ai`, `digital`, `accountability`, `governance`, `workforce`, `transparency`. Nearly every bill is some variation of "AI Governance and Workforce Transition Act."
**Why this matters:** A government that only legislates on one topic isn't a government â€” it's a subcommittee. This also explains why 77.7% of bills route to the Technology committee and Social Welfare got exactly 1 bill.

**Engine fix:**
- Diversify agent backstories and interests: some agents should care about healthcare, infrastructure, defense, education, trade, environment, housing, crime.
- Add "issue injection" events each tick that seed different policy areas: economic crisis, natural disaster, foreign policy tension, public health scare, infrastructure failure.
- Penalize duplicate topics: if there are already N active bills about "AI governance," reduce the probability of another one and increase the probability of an underrepresented topic.

***
## Finding 6: Provider Equity Is Skewed
5 Anthropic agents generated 6,059 decisions (avg 1,212/agent). 25 Ollama agents generated 6,042 decisions (avg 242/agent). Anthropic agents produce **5Ã— more decisions per agent** than Ollama agents.

**Latency profile confirms this:** Ollama is actually faster per-call (median 746ms vs 1,185ms), but Anthropic agents get dramatically more turns. This suggests the tick scheduler is either: (a) giving Anthropic agents more opportunities per tick, or (b) Ollama failures/timeouts are causing agents to miss turns entirely.
**Engine fix:**
- Audit `agentTick.ts` to confirm every active agent gets exactly one decision opportunity per tick per relevant phase.
- If an Ollama call fails or times out, log it but don't skip the agent's remaining phases in that tick.
- Track `decisions_per_agent_per_tick` as a metric and alert if the distribution becomes skewed.

***
## Finding 7: The Economy Is Ornamental
Agent balances range from M\$249 to M\$2,989, but money doesn't appear to constrain any behavior. Bills pass regardless of cost. Agents don't go broke. The treasury (M\$72,456) isn't being drawn down by enacted legislation.

**Engine fix:**
- Give bills an implementation cost. When a bill becomes law, deduct from the treasury. If the treasury is depleted, force austerity votes or tax increases.
- Let agents spend money on lobbying, campaigns, and coalition-building â€” and let running out of money actually constrain their options.
- Add economic feedback loops: some laws increase GDP/revenue, others increase spending. Let the budget become a genuine constraint that forces trade-offs.

***
## Simulation Activity Over Time
The timeline shows a healthy ramp from ~80 decisions/hour at launch to a sustained peak of ~1,100â€“1,300/hour, a clear gap during dev downtime (Feb 18 06:00â€“21:00 UTC), then restart with the new cohort coming online. The engine scales linearly with agent count and doesn't show degradation under load.

***
## Priority Matrix
| Priority | Issue | Severity | Effort | Impact on Credibility |
|----------|-------|----------|--------|----------------------|
| ðŸ”´ P0 | Action parse validation (Ollama hallucinations) | Data integrity | Low | High â€” researchers will immediately distrust unvalidated outputs |
| ðŸ”´ P0 | Ideological differentiation (3 blocs, not 5) | Sim realism | Medium | High â€” defeats the purpose of having alignments |
| ðŸŸ¡ P1 | Bill passage rate / legislative attrition | Sim realism | Medium | High â€” 94% passage is obviously unrealistic |
| ðŸŸ¡ P1 | Topic diversity in proposals | Sim realism | Low | Medium â€” monotopic legislature undermines generality |
| ðŸŸ¡ P1 | Approval rating compression | Differentiation | Low | Medium â€” flat ratings mean no political stakes |
| ðŸŸ¢ P2 | Agent activity balancing (Anthropic 5Ã— Ollama) | Fairness | Medium | Medium â€” skewed participation biases all analyses |
| ðŸŸ¢ P2 | Economic friction / budget as constraint | Depth | Medium | Lower â€” nice-to-have but not a credibility blocker |

***
## What's Missing from the Export
A data scientist would also want:

- **Party membership data** â€” which agents belong to which parties, when they joined/left
- **Forum posts** â€” the actual discourse content, not just decision logs
- **Government positions** â€” who holds which office at each point in time
- **Agent memory/reasoning traces** â€” the full LLM context that led to each decision, not just the parsed action
- **Config snapshot** â€” the exact runtime config (tick interval, probabilities, thresholds) active during this run, so the experiment is reproducible

Adding those tables to your export would immediately make this look like a research-grade dataset.

Sources
[1] agent-decisions.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/a5b0efb1-06fc-423f-824c-fd96e375c7fd/agent-decisions.csv
[2] agents-snapshot.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/abf2253a-1d31-4f67-87bc-8eaa8635e080/agents-snapshot.csv
[3] approval-events.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/2ceeffd6-c70a-438b-84e4-8f982e5ca185/approval-events.csv
[4] bill-votes.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/8b0d0f1c-e942-426e-98bd-130879f5bd2a/bill-votes.csv
[5] bills.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/66a8fbea-4af9-499f-a5f0-2f4a6e627f33/bills.csv
[6] elections.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/c336e9f3-100b-4e3c-a413-0d2fdfbe6830/elections.csv
[7] laws.csv https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/149478830/c4168db5-e0c4-4ec9-9a39-0ea6b9a8278d/laws.csv
